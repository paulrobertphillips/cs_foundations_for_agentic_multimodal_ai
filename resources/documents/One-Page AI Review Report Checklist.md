# âœ… One-Page AI Review Report Checklist

Below is a **one-page AI Review Report Checklist** designed to be:

* quick to apply
* copy-paste friendly
* usable with *any* AI tool
* aligned with everything you learned in Module 2

You can think of this as the *minimum viable governance layer* for AI-assisted engineering.

**For AI-Assisted Code & Data Science Work**

---

## 1ï¸âƒ£ Review Context (Required)

[] Review type clearly stated
Â Â Â Â Examples: refactor, bug fix, feature addition, integration change

[] Scope explicitly defined
Â Â Â Â What files / components were reviewed

[] Out-of-scope items explicitly listed
Â Â Â Â What was *not* reviewed or intentionally excluded

[] AI role declared
Â Â Â Â Example: â€œAI acting as constrained reviewerâ€

---

## 2ï¸âƒ£ Inputs Reviewed (Evidence)

[] Code files listed
Â Â Â Â Exact filenames or modules

[] Tests reviewed or executed
Â Â Â Â Test names or test suite

[] Reference artifacts included
Â Â Â Â Sprint plan, refactor plan, design notes (if applicable)

[] Inputs are complete
Â Â Â Â No undocumented assumptions about missing context

---

## 3ï¸âƒ£ Review Checks Performed

[] Scope adherence verified
Â Â Â Â No work outside approved sprint/refactor plan

[] Behavior preservation confirmed (if applicable)
Â Â Â Â Same inputs â†’ same outputs

[] Public interfaces checked
Â Â Â Â Function signatures, schemas, contracts unchanged

[] Dependency changes checked
Â Â Â Â No new dependencies unless approved

[] Configuration / invocation unchanged (if relevant)

---

## 4ï¸âƒ£ Test Evidence

[] Tests executed (Yes / No)

[] Test results recorded
Â Â Â Â Passed: ___
Â Â Â Â Failed: ___

[] New tests added?
Â Â Â Â If yes, list them
Â Â Â Â If no, explicitly state â€œNoneâ€

[] Known untested cases acknowledged

---

## 5ï¸âƒ£ Behavior & Interface Verification

[] Input formats unchanged

[] Output formats unchanged

[] Data contracts preserved

[] Error behavior unchanged (unless explicitly scoped)

[] Downstream consumers unaffected

---

## 6ï¸âƒ£ Findings Summary

[] Confirmed safe changes listed
Â Â Â Â (What *did* change)

[] Issues identified (if any)
Â Â Â Â Or explicitly state â€œNone observedâ€

[] Claims backed by evidence
Â Â Â Â No unsupported assertions

---

## 7ï¸âƒ£ Risk Assessment

[] Overall risk level stated
Â Â Â Â Low / Medium / High

[] Rationale provided
Â Â Â Â Why this risk level is appropriate

[] Mitigations identified (if needed)

[] Remaining unknowns acknowledged

---

## 8ï¸âƒ£ Review Limitations (Required)

[] Explicit statement of what this review does **not** guarantee

Examples:

* Performance under scale not evaluated
* Production environment behavior not tested
* Edge cases outside test coverage

[] No false sense of certainty conveyed

---

## 9ï¸âƒ£ Final Sanity Check

[] Review output is factual, not speculative

[] No refactor or improvement suggestions slipped in

[] Language is conservative and review-appropriate

[] A human could defend this review to a stakeholder

---

## ðŸ§  Rule of Thumb (Put This at the Bottom)

> **If a claim cannot be traced to code, tests, or an explicit assumption, it does not belong in the review.**

---

### How to Use This in Practice

* Paste this checklist into:

  * a PR description
  * a review prompt
  * a sprint artifact
  * a governance doc
* You do *not* need to fill every item every time â€” but you should **explicitly skip** items that donâ€™t apply.

---
